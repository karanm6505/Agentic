**
# Course Syllabus
## Course Title: Introduction to Deep Learning
**Course Code:** CS 345
**Credits:** 3
**Semester:** Fall 2024
**Instructor:** [Instructor Name Placeholder]
**Contact:** instructor.email@university.edu
**Office Hours:** Tuesdays and Thursdays 2:00 PM - 3:00 PM or By Appointment

### Course Description:
This course provides a comprehensive introduction to the field of deep learning. Students will gain a foundational understanding of the core concepts, architectures, and training techniques used in deep learning. The course will cover topics such as neural networks, backpropagation, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and optimization algorithms. Emphasis will be placed on both the theoretical underpinnings and practical implementation of deep learning models. Students will gain hands-on experience through programming assignments and a final project.

### Prerequisites:
Linear Algebra, Calculus, Programming in Python, Basic Probability and Statistics

### Learning Objectives:
1.  Understand the fundamental concepts of neural networks, including activation functions, loss functions, and optimization algorithms.
2.  Implement and train basic neural network architectures using a deep learning framework (e.g., TensorFlow, PyTorch).
3.  Analyze the principles behind backpropagation and its role in training deep learning models.
4.  Apply convolutional neural networks (CNNs) for image classification and object detection tasks.
5.  Develop recurrent neural networks (RNNs) for sequence modeling and natural language processing (NLP) tasks.
6.  Evaluate the performance of deep learning models using appropriate metrics and techniques.
7.  Design and implement a deep learning project to solve a real-world problem.

### Required Textbooks:
- Ian Goodfellow, Yoshua Bengio, and Aaron Courville, *Deep Learning*, MIT Press, 2016 (ISBN: 978-0262035613)

### Recommended Readings:
-   Andrew Ng, "Machine Learning" Coursera Course materials (available online)
-   "TensorFlow Tutorials" TensorFlow website (available online)

### Weekly Schedule:
**Week 1: Introduction to Deep Learning**
- Topics: Course overview, introduction to machine learning, history of deep learning, applications of deep learning.
- Readings: Chapter 1 of Goodfellow et al.
- Activities: Introduction to Python and relevant libraries (NumPy, Pandas), Discussion on applications.
- Due: N/A

**Week 2: Fundamentals of Neural Networks**
- Topics: Perceptrons, activation functions, feedforward networks, loss functions.
- Readings: Chapter 4 of Goodfellow et al.
- Activities: Programming assignment 1: Implementing a simple perceptron.
- Due: Programming Assignment 1

**Week 3: Training Neural Networks**
- Topics: Gradient descent, backpropagation, stochastic gradient descent (SGD), momentum.
- Readings: Chapter 5 and 6 of Goodfellow et al.
- Activities: Lab session on gradient descent optimization.
- Due: N/A

**Week 4: Regularization and Optimization**
- Topics: Regularization techniques (L1, L2), dropout, batch normalization, adaptive optimization algorithms (Adam, RMSprop).
- Readings: Chapter 7 and 8 of Goodfellow et al.
- Activities: Programming assignment 2: Implementing regularization techniques.
- Due: Programming Assignment 2

**Week 5: Convolutional Neural Networks (CNNs)**
- Topics: Convolutional layers, pooling layers, CNN architectures (LeNet, AlexNet, VGGNet).
- Readings: Chapter 9 of Goodfellow et al.
- Activities: Introduction to CNNs for image classification.
- Due: N/A

**Week 6: CNNs for Image Recognition**
- Topics: CNNs for Image classification, object detection, and image segmentation.
- Readings: Research papers on CNN architectures.
- Activities: Lab session: Implementing CNNs for image classification.
- Due: N/A

**Week 7: Recurrent Neural Networks (RNNs)**
- Topics: Recurrent layers, vanishing gradients, LSTM, GRU.
- Readings: Chapter 10 of Goodfellow et al.
- Activities: Introduction to RNNs for sequence modeling.
- Due: N/A

**Week 8: RNNs for Sequence Modeling**
- Topics: Applications of RNNs: Language modeling, sentiment analysis, machine translation.
- Readings: Research papers on RNN architectures.
- Activities: Programming assignment 3: Implementing RNNs.
- Due: Programming Assignment 3

**Week 9: Exam 1**
- Topics: Covers all topics from Week 1 to Week 8.
- Readings: Review all lecture notes and textbook chapters.
- Activities: Exam
- Due: Exam 1

**Week 10: Introduction to Autoencoders**
- Topics: Autoencoders, undercomplete autoencoders, variational autoencoders.
- Readings: Chapter 14 of Goodfellow et al.
- Activities: Discussion on autoencoder applications.
- Due: N/A

**Week 11: Deep Generative Models**
- Topics: Generative Adversarial Networks (GANs), applications.
- Readings: Research papers on GANs.
- Activities: Lab session on GANs.
- Due: N/A

**Week 12: Transfer Learning and Fine-tuning**
- Topics: Transfer learning, fine-tuning pre-trained models, domain adaptation.
- Readings: Research papers on transfer learning.
- Activities: Lab session on transfer learning.
- Due: N/A

**Week 13: Introduction to Reinforcement Learning**
- Topics: Markov Decision Processes, Q-learning, policy gradients.
- Readings: Chapter 13 of Goodfellow et al.
- Activities: Introduction to Reinforcement Learning applications.
- Due: N/A

**Week 14: Project Presentations and Discussion**
- Topics: Students present their project proposals.
- Readings: N/A
- Activities: Project presentation and discussion.
- Due: Project Proposal

**Week 15: Project Work and Support**
- Topics: Students continue working on their projects, instructor and TA support.
- Readings: N/A
- Activities: Project work and consultations.
- Due: N/A

**Week 16: Final Project Presentations and Conclusions**
- Topics: Final project presentations, course wrap-up, future directions in deep learning.
- Readings: N/A
- Activities: Final project presentations.
- Due: Final Project Report and Presentation

### Assessment Breakdown:
-   Exam 1: 25%
-   Programming Assignments (3): 30% (10% each)
-   Final Project: 35%
-   Class Participation: 10%

### Grading Scale:
A: 90-100%
B: 80-89%
C: 70-79%
D: 60-69%
F: Below 60%