**
# Course Syllabus
## Course Title: Natural Language Processing
**Course Code:** CS432
**Credits:** 3
**Semester:** Fall 2024
**Instructor:** [Instructor Name Placeholder]
**Contact:** [instructor.email@university.edu]
**Office Hours:** [Office Hours or By Appointment]

### Course Description:
This course provides an introduction to the fundamental concepts and techniques of Natural Language Processing (NLP). Students will learn how to process, analyze, and understand human language using computational methods. Topics include text analysis, language modeling, syntactic parsing, semantic analysis, and machine translation. The course emphasizes practical application through programming assignments and a final project.

### Prerequisites:
Data Structures, Basic Probability and Statistics, Python Programming

### Learning Objectives:
1.  Implement core NLP techniques such as tokenization, stemming, and part-of-speech tagging.
2.  Analyze text data using techniques like sentiment analysis and topic modeling.
3.  Build language models and apply them to text generation tasks.
4.  Apply syntactic parsing techniques to understand sentence structure.
5.  Understand the principles of machine translation and implement basic translation models.
6.  Evaluate the performance of NLP systems using appropriate metrics.

### Required Textbooks:
-   Jurafsky, D., & Martin, J. H. *Speech and Language Processing*. 3rd ed. draft, 2023.
-   Bird, S., Klein, E., & Loper, E. *Natural Language Processing with Python*. O'Reilly Media, 2009. (ISBN: 978-0596516499)

### Recommended Readings:
-   Li, Y., A Deep Reinforcement Learning Chatbot. *arXiv preprint arXiv:1701.06527*, 2017.
-   Vaswani, A., et al., Attention is All You Need. *Advances in Neural Information Processing Systems*, 2017.

### Weekly Schedule:
**Week 1: Introduction to Natural Language Processing**
-   Topics: What is NLP? History of NLP, Applications of NLP, Course Overview, NLP Pipeline
-   Readings: Jurafsky & Martin, Chapter 1
-   Activities: Introduction to Python and NLTK
-   Due: N/A

**Week 2: Text Preprocessing**
-   Topics: Tokenization, Stop Word Removal, Stemming, Lemmatization, Regular Expressions
-   Readings: Bird, Klein, & Loper, Chapter 3
-   Activities: Lab session on text preprocessing using NLTK
-   Due: N/A

**Week 3: Language Modeling**
-   Topics: N-grams, Smoothing Techniques (Add-k, Good-Turing), Evaluating Language Models (Perplexity)
-   Readings: Jurafsky & Martin, Chapter 4
-   Activities: Implement an N-gram language model
-   Due: N/A

**Week 4: Text Classification**
-   Topics: Naive Bayes, Sentiment Analysis, Feature Engineering
-   Readings: Bird, Klein, & Loper, Chapter 6
-   Activities: Build a sentiment classifier using Naive Bayes
-   Due: Programming Assignment 1 (Text Preprocessing and Language Modeling)

**Week 5: Part-of-Speech Tagging**
-   Topics: Hidden Markov Models (HMMs), Viterbi Algorithm, POS Tagging Evaluation
-   Readings: Jurafsky & Martin, Chapter 5
-   Activities: Implement a POS tagger using HMMs
-   Due: N/A

**Week 6: Syntactic Parsing**
-   Topics: Context-Free Grammars (CFGs), Top-Down and Bottom-Up Parsing, Dependency Parsing
-   Readings: Jurafsky & Martin, Chapter 12
-   Activities: Parse sentences using a CFG parser
-   Due: N/A

**Week 7: Semantic Analysis**
-   Topics: Word Sense Disambiguation (WSD), Semantic Role Labeling (SRL)
-   Readings: Jurafsky & Martin, Chapter 18, 21
-   Activities: Implement a WSD system
-   Due: N/A

**Week 8: Information Extraction**
-   Topics: Named Entity Recognition (NER), Relation Extraction
-   Readings: Jurafsky & Martin, Chapter 17
-   Activities: Build an NER system
-   Due: Programming Assignment 2 (POS Tagging and Syntactic Parsing)

**Week 9: Topic Modeling**
-   Topics: Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF)
-   Readings: David M. Blei, "Latent Dirichlet Allocation", 2003.
-   Activities: Apply LDA to a corpus of documents
-   Due: N/A

**Week 10: Machine Translation - Introduction**
-   Topics: Rule-Based Machine Translation, Statistical Machine Translation
-   Readings: Jurafsky & Martin, Chapter 25
-   Activities: Explore different MT approaches
-   Due: N/A

**Week 11: Machine Translation - Sequence-to-Sequence Models**
-   Topics: Encoder-Decoder Models, Attention Mechanisms
-   Readings: Vaswani et al., "Attention is All You Need", 2017.
-   Activities: Implement a sequence-to-sequence model for MT
-   Due: N/A

**Week 12: Machine Translation - Evaluation**
-   Topics: BLEU, METEOR, Human Evaluation
-   Readings: Jurafsky & Martin, Chapter 26
-   Activities: Evaluate the performance of an MT system
-   Due: Project Proposal

**Week 13: Project Work**
-   Topics: Individual project work
-   Readings: N/A
-   Activities: Project consultation with instructor
-   Due: N/A

**Week 14: Project Work**
-   Topics: Individual project work
-   Readings: N/A
-   Activities: Project consultation with instructor
-   Due: N/A

**Week 15: Project Presentations**
-   Topics: Student project presentations
-   Readings: N/A
-   Activities: Attend and evaluate project presentations
-   Due: N/A

**Week 16: Project Presentations**
-   Topics: Student project presentations
-   Readings: N/A
-   Activities: Attend and evaluate project presentations
-   Due: Final Project Report

### Assessment Breakdown:
*   Programming Assignments (40%): Two programming assignments focusing on implementing core NLP techniques.
*   NLP Project (60%): A final project involving the design, implementation, and evaluation of an NLP system. This includes a project proposal (5%), a final report (40%), and a project presentation (15%).

### Grading Scale:
A: 90-100%
B: 80-89%
C: 70-79%
D: 60-69%
F: Below 60%