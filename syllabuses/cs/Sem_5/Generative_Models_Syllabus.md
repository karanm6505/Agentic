**
# Course Syllabus
## Course Title: Generative Models
**Course Code:** CS490
**Credits:** 3
**Semester:** Fall 2024
**Instructor:** [Instructor Name Placeholder]
**Contact:** [instructor.email@university.edu]
**Office Hours:** [Office Hours or By Appointment]

### Course Description:
This course provides an introduction to generative models, a class of machine learning models that learn to generate new data instances that resemble the training data. We will explore a variety of generative modeling techniques, including Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Autoregressive Models, and Normalizing Flows. The course will cover the theoretical foundations of these models, as well as practical implementation details and applications in areas such as image generation, text generation, and music generation. Students will gain hands-on experience through programming assignments and a final project.

### Prerequisites:
Linear Algebra, Probability and Statistics, Machine Learning, Python Programming

### Learning Objectives:
1.  Understand the fundamental concepts and principles of generative models.
2.  Implement and train various generative models, including VAEs, GANs, and Autoregressive Models.
3.  Evaluate the performance of generative models using appropriate metrics.
4.  Apply generative models to solve real-world problems in areas such as image generation, text generation, and music generation.
5.  Critically analyze and compare different generative modeling techniques.
6.  Design and implement a novel generative model for a specific application.

### Required Textbooks:
- Goodfellow, I., Bengio, Y., & Courville, A. *Deep Learning*. MIT Press, 2016. (ISBN: 978-0262035613)

### Recommended Readings:
- Kingma, D. P., & Welling, M. *Auto-Encoding Variational Bayes*. ICLR, 2014.
- Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. *Generative Adversarial Nets*. NIPS, 2014.

### Weekly Schedule:
**Week 1: Introduction to Generative Models**
- Topics: What are generative models? Types of generative models, Applications of generative models.
- Readings: Deep Learning Book, Chapter 20
- Activities: Introduction to the course, setting up the development environment.
- Due: N/A

**Week 2: Probability and Information Theory Review**
- Topics: Basic probability concepts, Entropy, KL divergence, Maximum Likelihood Estimation.
- Readings: Deep Learning Book, Chapter 3
- Activities: Review of probability and information theory concepts.
- Due: N/A

**Week 3: Autoencoders**
- Topics: Introduction to Autoencoders, Undercomplete Autoencoders, Sparse Autoencoders.
- Readings: Deep Learning Book, Chapter 14
- Activities: Implementing a basic autoencoder.
- Due: N/A

**Week 4: Variational Autoencoders (VAEs)**
- Topics: Variational Inference, Reparameterization Trick, Training VAEs.
- Readings: Auto-Encoding Variational Bayes (Kingma & Welling, 2014)
- Activities: Implementing a VAE for image generation.
- Due: Programming Assignment 1: Autoencoders (Due Week 5)

**Week 5: Introduction to Generative Adversarial Networks (GANs)**
- Topics: The GAN framework, Generator and Discriminator networks, Training GANs.
- Readings: Generative Adversarial Nets (Goodfellow et al., 2014)
- Activities: Understanding the GAN training process.
- Due: N/A

**Week 6: GAN Architectures**
- Topics: Deep Convolutional GANs (DCGANs), Conditional GANs (CGANs).
- Readings: DCGAN paper, CGAN paper
- Activities: Implementing a DCGAN for image generation.
- Due: N/A

**Week 7: GAN Training Techniques**
- Topics: Mode collapse, Techniques for stabilizing GAN training, Wasserstein GANs (WGANs).
- Readings: WGAN paper
- Activities: Implementing WGAN.
- Due: Programming Assignment 2: GANs (Due Week 8)

**Week 8: Evaluation of Generative Models**
- Topics: Inception Score, Fr√©chet Inception Distance (FID).
- Readings: Research papers on evaluation metrics.
- Activities: Evaluating the performance of different GAN models.
- Due: N/A

**Week 9: Autoregressive Models**
- Topics: Introduction to Autoregressive Models, PixelRNN, PixelCNN.
- Readings: PixelRNN and PixelCNN papers
- Activities: Understanding autoregressive models for image generation.
- Due: N/A

**Week 10: Sequence Generation with Autoregressive Models**
- Topics: Language Models, Character-level RNNs, Byte-Pair Encoding (BPE).
- Readings: Research papers on language models
- Activities: Implementing a character-level RNN for text generation.
- Due: Programming Assignment 3: Autoregressive Models (Due Week 11)

**Week 11: Normalizing Flows**
- Topics: Change of Variables Formula, Planar Flows, Radial Flows.
- Readings: Papers on Normalizing Flows
- Activities: Understanding Normalizing Flows for density estimation.
- Due: N/A

**Week 12: Advanced Normalizing Flows**
- Topics: RealNVP, Glow.
- Readings: RealNVP and Glow papers
- Activities: Implementing a Normalizing Flow model.
- Due: N/A

**Week 13: Project Proposal Presentations**
- Topics: Students present their project proposals.
- Readings: N/A
- Activities: Project proposal presentations and feedback.
- Due: Project Proposal (Due at the beginning of Week 13)

**Week 14: Project Work**
- Topics: Students work on their final projects.
- Readings: N/A
- Activities: Individual meetings with the instructor.
- Due: N/A

**Week 15: Project Work**
- Topics: Students work on their final projects.
- Readings: N/A
- Activities: Individual meetings with the instructor.
- Due: N/A

**Week 16: Final Project Presentations**
- Topics: Students present their final projects.
- Readings: N/A
- Activities: Final project presentations.
- Due: Final Project Report and Code (Due at the end of Week 16)

### Assessment Breakdown:
- Programming Assignments (45%): Three programming assignments focusing on implementing and training different generative models.
- Final Project (55%): A final project involving the design, implementation, and evaluation of a novel generative model or application of existing models to a new problem.

### Grading Scale:
A: 90-100%
B: 80-89%
C: 70-79%
D: 60-69%
F: Below 60%