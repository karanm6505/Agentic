
# Course Syllabus
## Course Title: Bayesian Machine Learning
**Course Code:** STAT456
**Credits:** 3
**Semester:** Fall 2024
**Instructor:** [Instructor Name Placeholder]
**Contact:** [instructor.email@university.edu]
**Office Hours:** [Office Hours or By Appointment]

### Course Description:
This course provides an introduction to Bayesian approaches to machine learning. It covers the fundamental concepts of Bayesian inference and decision theory, and explores their application to a variety of machine learning tasks. Students will learn how to build and evaluate Bayesian models, and how to use them for prediction, classification, and clustering. The course emphasizes hands-on experience with Bayesian machine learning methods through programming assignments and a final project.

### Prerequisites:
Probability and Statistics, Linear Algebra, Calculus, Programming experience (Python preferred)

### Learning Objectives:
1.  Explain the core principles of Bayesian inference and decision theory.
2.  Implement Bayesian models for various machine learning tasks using Python.
3.  Compare and contrast Bayesian methods with frequentist approaches.
4.  Evaluate the performance of Bayesian models using appropriate metrics.
5.  Apply Bayesian methods to solve real-world machine learning problems.
6.  Design and implement a Bayesian machine learning project.

### Required Textbooks:
- Kevin P. Murphy, *Machine Learning: A Probabilistic Perspective*, MIT Press, 2012 (ISBN: 978-0262018029)

### Recommended Readings:
- Christopher Bishop, *Pattern Recognition and Machine Learning*, Springer, 2006.
- David Barber, *Bayesian Reasoning and Machine Learning*, Cambridge University Press, 2012.

### Weekly Schedule:
**Week 1: Introduction to Bayesian Machine Learning**
- Topics: What is Bayesian Machine Learning? Bayesian vs. Frequentist approaches. Review of Probability and Statistics.
- Readings: Murphy, Chapter 1
- Activities: Introduction to Python for Bayesian Machine Learning.
- Due: N/A

**Week 2: Bayesian Inference**
- Topics: Bayes' Theorem, Prior distributions, Likelihood functions, Posterior distributions, Conjugate priors.
- Readings: Murphy, Chapter 2
- Activities: Deriving posterior distributions for simple models.
- Due: N/A

**Week 3: Prior Distributions**
- Topics: Non-informative priors, informative priors, hierarchical priors, Empirical Bayes.
- Readings: Murphy, Chapter 3
- Activities: Choosing appropriate priors for different problems.
- Due: N/A

**Week 4: Bayesian Model Selection**
- Topics: Model selection criteria (AIC, BIC), Bayes factors, Cross-validation.
- Readings: Murphy, Chapter 4
- Activities: Comparing different models using Bayes factors.
- Due: Programming Assignment 1: Implementing Bayesian Inference for a Simple Model

**Week 5: Bayesian Linear Regression**
- Topics: Linear regression with Gaussian priors, Posterior predictive distribution.
- Readings: Murphy, Chapter 7
- Activities: Implementing Bayesian linear regression.
- Due: N/A

**Week 6: Bayesian Classification**
- Topics: Logistic regression with Bayesian priors, Gaussian process classification.
- Readings: Murphy, Chapter 8
- Activities: Implementing Bayesian logistic regression.
- Due: N/A

**Week 7: Markov Chain Monte Carlo (MCMC)**
- Topics: Introduction to MCMC methods, Metropolis-Hastings algorithm, Gibbs sampling.
- Readings: Murphy, Chapter 11
- Activities: Implementing Metropolis-Hastings algorithm.
- Due: N/A

**Week 8: MCMC Applications**
- Topics: Applying MCMC to Bayesian models, Convergence diagnostics.
- Readings: Murphy, Chapter 12
- Activities: Using MCMC to sample from posterior distributions.
- Due: Programming Assignment 2: Bayesian Linear Regression with MCMC

**Week 9: Gaussian Processes**
- Topics: Gaussian process regression, Gaussian process classification.
- Readings: Murphy, Chapter 15
- Activities: Implementing Gaussian process regression.
- Due: N/A

**Week 10: Bayesian Nonparametrics**
- Topics: Dirichlet process mixtures, Chinese restaurant process.
- Readings: Murphy, Chapter 16
- Activities: Exploring Dirichlet process mixtures.
- Due: N/A

**Week 11: Variational Inference**
- Topics: Introduction to variational inference, Mean field approximation.
- Readings: Murphy, Chapter 10
- Activities: Implementing variational inference for simple models.
- Due: Project Proposal Due

**Week 12: Variational Inference Applications**
- Topics: Applying variational inference to Bayesian models.
- Readings: Murphy, Chapter 10
- Activities: Using variational inference to approximate posterior distributions.
- Due: N/A

**Week 13: Bayesian Deep Learning**
- Topics: Bayesian Neural Networks, Dropout as Bayesian Approximation.
- Readings: Research Papers on Bayesian Deep Learning
- Activities: Implementing a simple Bayesian Neural Network.
- Due: N/A

**Week 14: Model Criticism and Evaluation**
- Topics: Posterior predictive checks, Calibration, Sensitivity analysis.
- Readings: Murphy, Chapter 6
- Activities: Evaluating the performance of Bayesian models.
- Due: Programming Assignment 3: Implementing Gaussian Processes

**Week 15: Project Work**
- Topics: Working on final projects.
- Readings: N/A
- Activities: Project consultations with the instructor.
- Due: N/A

**Week 16: Project Presentations**
- Topics: Project presentations.
- Readings: N/A
- Activities: Student presentations.
- Due: Final Project Due

### Assessment Breakdown:
*   Programming Assignments (45%): Three programming assignments designed to provide hands-on experience with Bayesian methods.
*   Final Project (55%): A final project where students apply Bayesian methods to a problem of their choice.

### Grading Scale:
A: 90-100%
B: 80-89%
C: 70-79%
D: 60-69%
F: Below 60%